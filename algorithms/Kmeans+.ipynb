{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17707,"status":"ok","timestamp":1668445295774,"user":{"displayName":"孙菲阳","userId":"00080526783451141965"},"user_tz":-60},"id":"WAi8dgc-J5Jn","outputId":"30dfbcaf-271f-49d4-e455-959ebdbae8f0"},"outputs":[],"source":["%matplotlib inline\n","# from ExKMC.Tree import Tree # import from cloned local library followed by installing manually\n","import sys\n","sys.path.append('../')\n","from ExKMC_M.ExKMC.Tree import Tree\n","\n","from sklearn.datasets import make_blobs\n","import gdown\n","import pandas as pd\n","import copy\n","from sklearn.cluster import KMeans,DBSCAN,BisectingKMeans,MiniBatchKMeans\n","from utils import calc_cost, plot_kmeans, plot_tree_boundary,plot_confusion_matrix\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.preprocessing import StandardScaler, normalize\n","from utils import plot_confusion_matrix\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import os\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","from sklearn.utils import check_random_state, check_X_y, _safe_indexing\n","from sklearn.metrics.pairwise import pairwise_distances, pairwise_distances_chunked\n","from sklearn.preprocessing import LabelEncoder\n","import functools\n","from sklearn.feature_selection import SelectKBest, mutual_info_regression,mutual_info_classif\n","\n","from sklearn.decomposition import PCA,SparsePCA,MiniBatchSparsePCA\n"]},{"cell_type":"markdown","metadata":{},"source":["## data preprocessing"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# input data\n","def getDataDrive(url, output, isImport=False):\n","    \"\"\"\n","    return pandas dataframe\n","    \"\"\"\n","    if isImport:\n","        gdown.download(url=url, output=output, quiet=False)\n","    res = pd.read_csv(output)\n","    return res\n","\n","\n","neg = getDataDrive(\n","    url=\"https://drive.google.com/uc?id=1ocidTn7jUvCrLG_XJ6H9MiNUDexCkjFG\",\n","    output=\"/home/sfy/Documents/VScodeProject/Thesis/data/negtive.csv\",\n",")\n","pos = getDataDrive(\n","    url=\"https://drive.google.com/uc?id=1IyMPjACBkz96giGJ-Z4IMk-qzM-1CJ9G\",\n","    output=\"/home/sfy/Documents/VScodeProject/Thesis/data/positive.csv\",\n",")\n","\n","X_neg = copy.deepcopy(neg)\n","X_pos = copy.deepcopy(pos)\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["pos_target = [0 for _ in range(X_pos.shape[0])]\n","neg_target = [1 for _ in range(X_neg.shape[0])]\n","\n","X_pos[\"y\"] = pos_target\n","X_neg[\"y\"] = neg_target\n","\n","X__ = pd.concat([X_pos, X_neg])\n","\n","# exclue name -> X_\n","X_ = X__.loc[:, X__.columns != \"name\"]\n","\n","# exclude label -> X\n","y = X_[\"y\"]\n","X = X_.loc[:, X_.columns != \"y\"]"]},{"cell_type":"markdown","metadata":{},"source":["## evaluation"]},{"cell_type":"markdown","metadata":{},"source":["### fscore and accuracy"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def f_a_score(true_labels,kmenas_labels,tree_labels):\n","    from sklearn.metrics import f1_score,accuracy_score\n","    print(f'fsocre of kmenas is {f1_score(y_true=true_labels,y_pred=kmenas_labels)}')\n","    print(f'fsocre of tree score is {f1_score(y_true=true_labels,y_pred=tree_labels)}')\n","\n","    print(f'accuracy of kmenas is {accuracy_score(y_true=true_labels,y_pred=kmenas_labels)}')\n","    print(f'accuracy of tree score is {accuracy_score(y_true=true_labels,y_pred=tree_labels)}')\n","\n","from sklearn.feature_selection import VarianceThreshold,GenericUnivariateSelect,chi2\n","\n","\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=0)\n","k=2\n","X_train = X\n","X_train.shape"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["fsocre of kmenas is 0.6793022754053739\n","fsocre of tree score is 0.6779784710819193\n","accuracy of kmenas is 0.5316431151077393\n","accuracy of tree score is 0.5294131904888867\n"]}],"source":["# success with variance\n","scaler = StandardScaler()\n","scaled_df = scaler.fit_transform(X_train)\n","\n","# Converting the numpy array into a pandas DataFrame\n","X_train_ = pd.DataFrame(scaled_df)\n","\n","X_train_ = VarianceThreshold(.8*(1-.8)).fit_transform(X_train_)\n","\n","kmeans = KMeans(k)\n","\n","kmeans_labels = kmeans.fit_predict(X_train_)\n","\n","tree = Tree(k=k,max_leaves=16 * k)\n","tree_labels = tree.fit_predict(X_train_, kmeans)\n","\n","f_a_score(y, kmeans_labels, tree_labels=tree_labels)\n"]},{"cell_type":"code","execution_count":111,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["fsocre of kmenas is 0.5051308711179422\n","fsocre of tree score is 0.5307182751006624\n","accuracy of kmenas is 0.46932641733524005\n","accuracy of tree score is 0.4745618925273287\n"]}],"source":["#random result"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","def _silhouette_reduce(D_chunk, start, labels, label_freqs):\n","    \"\"\"Accumulate silhouette statistics for vertical chunk of X.\n","\n","    Parameters\n","    ----------\n","    D_chunk : array-like of shape (n_chunk_samples, n_samples)\n","        Precomputed distances for a chunk.\n","    start : int\n","        First index in the chunk.\n","    labels : array-like of shape (n_samples,)\n","        Corresponding cluster labels, encoded as {0, ..., n_clusters-1}.\n","    label_freqs : array-like\n","        Distribution of cluster labels in ``labels``.\n","    \"\"\"\n","    # accumulate distances from each sample to each cluster\n","    clust_dists = np.zeros((len(D_chunk), len(label_freqs)), dtype=D_chunk.dtype)\n","    for i in range(len(D_chunk)):\n","        clust_dists[i] += np.bincount(\n","            labels, weights=D_chunk[i], minlength=len(label_freqs)\n","        )\n","\n","    # intra_index selects intra-cluster distances within clust_dists\n","    intra_index = (np.arange(len(D_chunk)), labels[start : start + len(D_chunk)])\n","    # intra_clust_dists are averaged over cluster size outside this function\n","    intra_clust_dists = clust_dists[intra_index]\n","    # of the remaining distances we normalise and extract the minimum\n","    clust_dists[intra_index] = np.inf\n","    clust_dists /= label_freqs\n","    inter_clust_dists = clust_dists.min(axis=1)\n","    return intra_clust_dists, inter_clust_dists\n","\n","\n","def silhouette_score(\n","    X, labels, *, metric=\"euclidean\", sample_size=None, random_state=None, **kwds\n","):\n","    if sample_size is not None:\n","        X, labels = check_X_y(X, labels, accept_sparse=[\"csc\", \"csr\"])\n","        random_state = check_random_state(random_state)\n","        indices = random_state.permutation(X.shape[0])[:sample_size]\n","        if metric == \"precomputed\":\n","            X, labels = X[indices].T[indices].T, labels[indices]\n","        else:\n","            X, labels = X[indices], labels[indices]\n","    else:\n","        scores = silhouette_samples(X, labels, metric=metric, **kwds)\n","    return np.mean(scores,axis=1)\n","\n","\n","def silhouette_samples(X, labels, *, metric=\"euclidean\", **kwds):\n","    \"\"\"Compute the Silhouette Coefficient for each sample.\n","\n","    The Silhouette Coefficient is a measure of how well samples are clustered\n","    with samples that are similar to themselves. Clustering models with a high\n","    Silhouette Coefficient are said to be dense, where samples in the same\n","    cluster are similar to each other, and well separated, where samples in\n","    different clusters are not very similar to each other.\n","\n","    The Silhouette Coefficient is calculated using the mean intra-cluster\n","    distance (``a``) and the mean nearest-cluster distance (``b``) for each\n","    sample.  The Silhouette Coefficient for a sample is ``(b - a) / max(a,\n","    b)``.\n","    Note that Silhouette Coefficient is only defined if number of labels\n","    is 2 ``<= n_labels <= n_samples - 1``.\n","\n","    This function returns the Silhouette Coefficient for each sample.\n","\n","    The best value is 1 and the worst value is -1. Values near 0 indicate\n","    overlapping clusters.\n","    \"\"\"\n","    X, labels = check_X_y(X, labels, accept_sparse=[\"csc\", \"csr\"])\n","\n","    # Check for non-zero diagonal entries in precomputed distance matrix\n","    if metric == \"precomputed\":\n","        error_msg = ValueError(\n","            \"The precomputed distance matrix contains non-zero \"\n","            \"elements on the diagonal. Use np.fill_diagonal(X, 0).\"\n","        )\n","        if X.dtype.kind == \"f\":\n","            atol = np.finfo(X.dtype).eps * 100\n","            if np.any(np.abs(np.diagonal(X)) > atol):\n","                raise ValueError(error_msg)\n","        elif np.any(np.diagonal(X) != 0):  # integral dtype\n","            raise ValueError(error_msg)\n","\n","    le = LabelEncoder()\n","    labels = le.fit_transform(labels)\n","    n_samples = len(labels)\n","    label_freqs = np.bincount(labels)\n","\n","    kwds[\"metric\"] = metric\n","    reduce_func = functools.partial(\n","        _silhouette_reduce, labels=labels, label_freqs=label_freqs\n","    )\n","    results = zip(*pairwise_distances_chunked(X, reduce_func=reduce_func, **kwds))\n","    intra_clust_dists, inter_clust_dists = results\n","    # intra:35655.59,inter:1.559\n","    intra_clust_dists = np.concatenate(intra_clust_dists)\n","    inter_clust_dists = np.concatenate(inter_clust_dists)\n","# unknow operatino of denom # after denom the dists become 1.49 before is 30234\n","    denom = (label_freqs - 1).take(labels, mode=\"clip\")\n","    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n","        intra_clust_dists /= denom\n","\n","    sil_samples = inter_clust_dists - intra_clust_dists\n","    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n","        sil_samples /= np.maximum(intra_clust_dists, inter_clust_dists)\n","    # nan values are for clusters of size 1, and should be 0\n","    return [intra_clust_dists,inter_clust_dists,np.nan_to_num(sil_samples)]\n","\n","\n","# print(f'intra and inter distance of kmenas is {silhouette_score(X=X_train, labels=kmeans_labels)}')\n","# print(f'intra and inter distance of tree score is {silhouette_score(X=X_train, labels=tree_labels)}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# cost\n","# kmeas cost in paper: The k-means cost is the sum of squared distances of each point to the mean of points associated with the cluster.\n","# kmenas cost in sklearn:Opposite of the value of X on the K-means objective.\n","# surrogate cost:The k-means surrogate cost is the sum of squared distances of each point to the closest center of the kmeans given (or trained) in the fit method.k-means surrogate cost > k-means cost, as k-means cost is computed with respect to the optimal centers.\n","\n","kmeas_cost = tree.score(X_train)\n","surrogate_score = tree.surrogate_score(X_train)\n","print(\n","    f\"kmeans_cost is {kmeas_cost} \\nsurrogate_score is {surrogate_score}\\nkmenas cost in surrogate is {kmeans.score(X_train)}\"\n",")\n","\n","#test with distancs munally\n","# inter-distance\n","from scipy.spatial.distance import euclidean\n","\n","dst = euclidean(kmeans.cluster_centers_[0], kmeans.cluster_centers_[1])\n","print(f\"inter distance from kmeans:{dst}\")\n","\n","tree_centers = tree.get_centers()\n","tree_dst = euclidean(tree_centers[0], tree_centers[1])\n","print(f\"inter distance from tree:{tree_dst}\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNrV8z86W1ElNSu4E21X3YW","provenance":[]},"kernelspec":{"display_name":"Python 3.8.15 ('thesis8')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"},"vscode":{"interpreter":{"hash":"518c84c64c8714e835d71f45ff9dbbd66c2334f2195057bfe969113e9082ddb2"}}},"nbformat":4,"nbformat_minor":0}
