{"cells":[{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17707,"status":"ok","timestamp":1668445295774,"user":{"displayName":"孙菲阳","userId":"00080526783451141965"},"user_tz":-60},"id":"WAi8dgc-J5Jn","outputId":"30dfbcaf-271f-49d4-e455-959ebdbae8f0"},"outputs":[],"source":["%matplotlib inline\n","# from ExKMC.Tree import Tree # import from cloned local library followed by installing manually\n","import sys\n","sys.path.append('../')\n","from ExKMC_M.ExKMC.Tree import Tree\n","\n","from sklearn.datasets import make_blobs\n","import gdown\n","import pandas as pd\n","import copy\n","from sklearn.cluster import KMeans\n","from utils import calc_cost, plot_kmeans, plot_tree_boundary,plot_confusion_matrix\n","from sklearn.preprocessing import StandardScaler, normalize\n","from utils import plot_confusion_matrix\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import os\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# print(os.path.join(os.path.dirname(__file__),\"./data/negtive.csv\"))\n","# print(os.path.join(os.path.abspath('algorithms/Kmeans+.ipynb'),\"./data/negtive.csv\"))\n","# print(os.path.abspath('algorithms/Kmeans+.ipynb'))\n"]},{"cell_type":"markdown","metadata":{},"source":["## data preprocessing"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# input data\n","def getDataDrive(url, output, isImport=False):\n","    \"\"\"\n","    return pandas dataframe\n","    \"\"\"\n","    if isImport:\n","        gdown.download(url=url, output=output, quiet=False)\n","    res = pd.read_csv(output)\n","    return res\n","\n","\n","neg = getDataDrive(\n","    url=\"https://drive.google.com/uc?id=1ocidTn7jUvCrLG_XJ6H9MiNUDexCkjFG\",\n","    output=\"/home/sfy/Documents/VScodeProject/Thesis/data/negtive.csv\",\n",")\n","pos = getDataDrive(\n","    url=\"https://drive.google.com/uc?id=1IyMPjACBkz96giGJ-Z4IMk-qzM-1CJ9G\",\n","    output=\"/home/sfy/Documents/VScodeProject/Thesis/data/positive.csv\",\n",")\n","\n","X_neg = copy.deepcopy(neg)\n","X_pos = copy.deepcopy(pos)\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["pos_target = [1 for _ in range(X_pos.shape[0])]\n","neg_target = [0 for _ in range(X_neg.shape[0])]\n","\n","X_pos[\"y\"] = pos_target\n","X_neg[\"y\"] = neg_target\n","\n","X__ = pd.concat([X_pos, X_neg])\n","\n","# exclue name -> X_\n","X_ = X__.loc[:, X__.columns != \"name\"]\n","\n","# exclude label -> X\n","y = X_[\"y\"]\n","X = X_.loc[:, X_.columns != \"y\"]\n","\n","# data preprocess\n","# Standardize data\n","# TODO train_test_split(X, y, test_size=0.4, random_state=0)\n","\n","scaler = StandardScaler()\n","scaled_df = scaler.fit_transform(X)\n","\n","# Normalizing the Data\n","normalized_df = normalize(scaled_df)\n","\n","# Converting the numpy array into a pandas DataFrame\n","X = pd.DataFrame(normalized_df)\n"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"data":{"text/plain":["(41257, 696)"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["X.shape\n"]},{"cell_type":"markdown","metadata":{},"source":["## ExKMC algorithm"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# kmeans pre train\n","k = 2\n","n = X.shape[0]\n","\n","\n","kmeans = KMeans(k, random_state=42)\n","kmeans.fit(X)\n","\n","# confusion_matrix\n","# plot_confusion_matrix(y, kmeans.predict(X), np.array(list(X_.columns)), normalize=True)\n","\n","\n","def visualize_2d(data):\n","    from sklearn.decomposition import PCA\n","\n","    pca = PCA(2)\n","    df = pca.fit_transform(data.to_numpy())\n","\n","    kmeans_2 = KMeans(k, random_state=42)\n","    kmeans_2.fit(df)\n","\n","    plot_kmeans(kmeans_2, x_data=df)\n","\n","    tree_n = Tree(k)\n","    tree_n.fit(df, kmeans_2)\n","\n","    plot_tree_boundary(tree_n, k, df, kmeans_2, plot_mistakes=True)\n","\n","\n","# visualize_2d(X)\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["cluster_labels = kmeans.fit_predict(X)\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["array([[-0.00569809, -0.0144497 , -0.01241951, ...,  0.        ,\n","         0.        ,  0.        ],\n","       [-0.03171698, -0.01341128, -0.00573732, ...,  0.        ,\n","         0.        ,  0.        ]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["kmeans.cluster_centers_\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["13"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["kmeans.n_iter_\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# test with inter\n","def inter_visual():\n","    from yellowbrick.cluster import InterclusterDistance\n","\n","    visualizer = InterclusterDistance(kmeans)\n","    visualizer.fit(X)\n","    visualizer.show()\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["<ExKMC_M.ExKMC.Tree.Tree at 0x7f84b62bbd30>"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize tree with up to 6 leaves, predicting 3 clusters\n","tree = Tree(k=k)\n","\n","# Construct the tree, and return cluster labels\n","# prediction = tree.fit_predict(X,kmeans)\n","tree.fit(X, kmeans)\n","\n","# Tree plot saved to filename\n","# tree.plot(\"test\",feature_names=list(X_.columns))\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["tree_labels = tree.fit_predict(X, kmeans)\n"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"data":{"text/plain":["array([0., 0., 0., ..., 0., 0., 1.])"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["tree_labels\n"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["kmeans_cost is 37179.87612739552 \n","surrogate_score is 37290.76841843778\n","kmenas cost in surrogate is -36683.55002984239\n"]}],"source":["# cost\n","# kmeas cost in paper: The k-means cost is the sum of squared distances of each point to the mean of points associated with the cluster.\n","# kmenas cost in sklearn:Opposite of the value of X on the K-means objective.\n","# surrogate cost:The k-means surrogate cost is the sum of squared distances of each point to the closest center of the kmeans given (or trained) in the fit method.k-means surrogate cost > k-means cost, as k-means cost is computed with respect to the optimal centers.\n","\n","kmeas_cost = tree.score(X)\n","surrogate_score = tree.surrogate_score(X)\n","print(\n","    f\"kmeans_cost is {kmeas_cost} \\nsurrogate_score is {surrogate_score}\\nkmenas cost in surrogate is {kmeans.score(X)}\"\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation"]},{"cell_type":"markdown","metadata":{},"source":["### inter distance"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["inter distance from kmeans:0.5800166565176593\n","inter distance from tree:0.5800166565176593\n"]}],"source":["# inter-distance\n","from scipy.spatial.distance import euclidean\n","\n","dst = euclidean(kmeans.cluster_centers_[0], kmeans.cluster_centers_[1])\n","print(f\"inter distance from kmeans:{dst}\")\n","\n","tree_centers = tree.get_centers()\n","tree_dst = euclidean(tree_centers[0], tree_centers[1])\n","print(f\"inter distance from tree:{tree_dst}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### intra distance"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.utils import check_random_state, check_X_y, _safe_indexing\n","from sklearn.metrics.pairwise import pairwise_distances, pairwise_distances_chunked\n","from sklearn.preprocessing import LabelEncoder\n","import functools\n"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[],"source":["def _silhouette_reduce(D_chunk, start, labels, label_freqs):\n","    \"\"\"Accumulate silhouette statistics for vertical chunk of X.\n","\n","    Parameters\n","    ----------\n","    D_chunk : array-like of shape (n_chunk_samples, n_samples)\n","        Precomputed distances for a chunk.\n","    start : int\n","        First index in the chunk.\n","    labels : array-like of shape (n_samples,)\n","        Corresponding cluster labels, encoded as {0, ..., n_clusters-1}.\n","    label_freqs : array-like\n","        Distribution of cluster labels in ``labels``.\n","    \"\"\"\n","    # accumulate distances from each sample to each cluster\n","    clust_dists = np.zeros((len(D_chunk), len(label_freqs)), dtype=D_chunk.dtype)\n","    for i in range(len(D_chunk)):\n","        clust_dists[i] += np.bincount(\n","            labels, weights=D_chunk[i], minlength=len(label_freqs)\n","        )\n","\n","    # intra_index selects intra-cluster distances within clust_dists\n","    intra_index = (np.arange(len(D_chunk)), labels[start : start + len(D_chunk)])\n","    # intra_clust_dists are averaged over cluster size outside this function\n","    intra_clust_dists = clust_dists[intra_index]\n","    # of the remaining distances we normalise and extract the minimum\n","    clust_dists[intra_index] = np.inf\n","    clust_dists /= label_freqs\n","    inter_clust_dists = clust_dists.min(axis=1)\n","    return intra_clust_dists, inter_clust_dists\n","\n","\n","def silhouette_score(\n","    X, labels, *, metric=\"euclidean\", sample_size=None, random_state=None, **kwds\n","):\n","    if sample_size is not None:\n","        X, labels = check_X_y(X, labels, accept_sparse=[\"csc\", \"csr\"])\n","        random_state = check_random_state(random_state)\n","        indices = random_state.permutation(X.shape[0])[:sample_size]\n","        if metric == \"precomputed\":\n","            X, labels = X[indices].T[indices].T, labels[indices]\n","        else:\n","            X, labels = X[indices], labels[indices]\n","    else:\n","        scores = silhouette_samples(X, labels, metric=metric, **kwds)\n","    return np.mean(scores,axis=1)\n","\n","\n","def silhouette_samples(X, labels, *, metric=\"euclidean\", **kwds):\n","    \"\"\"Compute the Silhouette Coefficient for each sample.\n","\n","    The Silhouette Coefficient is a measure of how well samples are clustered\n","    with samples that are similar to themselves. Clustering models with a high\n","    Silhouette Coefficient are said to be dense, where samples in the same\n","    cluster are similar to each other, and well separated, where samples in\n","    different clusters are not very similar to each other.\n","\n","    The Silhouette Coefficient is calculated using the mean intra-cluster\n","    distance (``a``) and the mean nearest-cluster distance (``b``) for each\n","    sample.  The Silhouette Coefficient for a sample is ``(b - a) / max(a,\n","    b)``.\n","    Note that Silhouette Coefficient is only defined if number of labels\n","    is 2 ``<= n_labels <= n_samples - 1``.\n","\n","    This function returns the Silhouette Coefficient for each sample.\n","\n","    The best value is 1 and the worst value is -1. Values near 0 indicate\n","    overlapping clusters.\n","\n","    Read more in the :ref:`User Guide <silhouette_coefficient>`.\n","\n","    Parameters\n","    ----------\n","    X : array-like of shape (n_samples_a, n_samples_a) if metric == \\\n","            \"precomputed\" or (n_samples_a, n_features) otherwise\n","        An array of pairwise distances between samples, or a feature array.\n","\n","    labels : array-like of shape (n_samples,)\n","        Label values for each sample.\n","\n","    metric : str or callable, default='euclidean'\n","        The metric to use when calculating distance between instances in a\n","        feature array. If metric is a string, it must be one of the options\n","        allowed by :func:`sklearn.metrics.pairwise.pairwise_distances`.\n","        If ``X`` is the distance array itself, use \"precomputed\" as the metric.\n","        Precomputed distance matrices must have 0 along the diagonal.\n","\n","    **kwds : optional keyword parameters\n","        Any further parameters are passed directly to the distance function.\n","        If using a ``scipy.spatial.distance`` metric, the parameters are still\n","        metric dependent. See the scipy docs for usage examples.\n","\n","    Returns\n","    -------\n","    silhouette : array-like of shape (n_samples,)\n","        Silhouette Coefficients for each sample.\n","    \"\"\"\n","    X, labels = check_X_y(X, labels, accept_sparse=[\"csc\", \"csr\"])\n","\n","    # Check for non-zero diagonal entries in precomputed distance matrix\n","    if metric == \"precomputed\":\n","        error_msg = ValueError(\n","            \"The precomputed distance matrix contains non-zero \"\n","            \"elements on the diagonal. Use np.fill_diagonal(X, 0).\"\n","        )\n","        if X.dtype.kind == \"f\":\n","            atol = np.finfo(X.dtype).eps * 100\n","            if np.any(np.abs(np.diagonal(X)) > atol):\n","                raise ValueError(error_msg)\n","        elif np.any(np.diagonal(X) != 0):  # integral dtype\n","            raise ValueError(error_msg)\n","\n","    le = LabelEncoder()\n","    labels = le.fit_transform(labels)\n","    n_samples = len(labels)\n","    label_freqs = np.bincount(labels)\n","\n","    kwds[\"metric\"] = metric\n","    reduce_func = functools.partial(\n","        _silhouette_reduce, labels=labels, label_freqs=label_freqs\n","    )\n","    results = zip(*pairwise_distances_chunked(X, reduce_func=reduce_func, **kwds))\n","    intra_clust_dists, inter_clust_dists = results\n","    # intra:35655.59,inter:1.559\n","    intra_clust_dists = np.concatenate(intra_clust_dists)\n","    inter_clust_dists = np.concatenate(inter_clust_dists)\n","# unknow operatino of denom # after denom the dists become 1.49 before is 30234\n","    denom = (label_freqs - 1).take(labels, mode=\"clip\")\n","    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n","        intra_clust_dists /= denom\n","\n","    sil_samples = inter_clust_dists - intra_clust_dists\n","    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n","        sil_samples /= np.maximum(intra_clust_dists, inter_clust_dists)\n","    # nan values are for clusters of size 1, and should be 0\n","    return [intra_clust_dists,inter_clust_dists,np.nan_to_num(sil_samples)]\n","\n","\n"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["intra and inter distance of kmenas is [1.31764123 1.44071873 0.08424813]\n","intra and inter distance of tree score is [1.32618905 1.42629196 0.06896391]\n"]}],"source":["print(f'intra and inter distance of kmenas is {silhouette_score(X=X, labels=cluster_labels)}')\n","print(f'intra and inter distance of tree score is {silhouette_score(X=X, labels=tree_labels)}')\n"]},{"cell_type":"markdown","metadata":{},"source":["### fscore and accuracy"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["fsocre of kmenas is 0.427936872909699\n","fsocre of tree score is 0.40313876651982383\n","accuracy of kmenas is 0.46932641733524005\n","accuracy of tree score is 0.4745618925273287\n"]}],"source":["from sklearn.metrics import f1_score,accuracy_score\n","print(f'fsocre of kmenas is {f1_score(y_true=y,y_pred=cluster_labels)}')\n","print(f'fsocre of tree score is {f1_score(y_true=y,y_pred=tree_labels)}')\n","\n","print(f'accuracy of kmenas is {accuracy_score(y_true=y,y_pred=cluster_labels)}')\n","print(f'accuracy of tree score is {accuracy_score(y_true=y,y_pred=tree_labels)}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNrV8z86W1ElNSu4E21X3YW","provenance":[]},"kernelspec":{"display_name":"Python 3.8.15 ('thesis8')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"},"vscode":{"interpreter":{"hash":"518c84c64c8714e835d71f45ff9dbbd66c2334f2195057bfe969113e9082ddb2"}}},"nbformat":4,"nbformat_minor":0}
