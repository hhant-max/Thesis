{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17707,"status":"ok","timestamp":1668445295774,"user":{"displayName":"孙菲阳","userId":"00080526783451141965"},"user_tz":-60},"id":"WAi8dgc-J5Jn","outputId":"30dfbcaf-271f-49d4-e455-959ebdbae8f0"},"outputs":[],"source":["%matplotlib inline\n","from ExKMC.Tree import Tree\n","from sklearn.datasets import make_blobs\n","import gdown\n","import pandas as pd\n","import copy\n","from sklearn.cluster import KMeans\n","from utils import calc_cost, plot_kmeans, plot_tree_boundary,plot_confusion_matrix\n","from sklearn.preprocessing import StandardScaler, normalize\n","from utils import plot_confusion_matrix\n","import numpy as np\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"markdown","metadata":{},"source":["## data preprocessing"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# input data\n","def getDataDrive(url, output, isImport=False):\n","    \"\"\"\n","    return pandas dataframe\n","    \"\"\"\n","    if isImport:\n","        gdown.download(url=url, output=output, quiet=False)\n","    res = pd.read_csv(output)\n","    return res\n","\n","\n","neg = getDataDrive(\n","    url=\"https://drive.google.com/uc?id=1ocidTn7jUvCrLG_XJ6H9MiNUDexCkjFG\",\n","    output=\"./data/negtive.csv\",\n",")\n","pos = getDataDrive(\n","    url=\"https://drive.google.com/uc?id=1IyMPjACBkz96giGJ-Z4IMk-qzM-1CJ9G\",\n","    output=\"./data/positive.csv\",\n",")\n","\n","X_neg = copy.deepcopy(neg)\n","X_pos = copy.deepcopy(pos)\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["pos_target = [1 for _ in range(X_pos.shape[0])]\n","neg_target = [0 for _ in range(X_neg.shape[0])]\n","\n","X_pos['y'] = pos_target\n","X_neg['y'] = neg_target\n","\n","X__ = pd.concat([X_pos,X_neg])\n","\n","# exclue name -> X_\n","X_ = X__.loc[:, X__.columns!='name']\n","\n","# exclude label -> X\n","y = X_['y']\n","X = X_.loc[:, X_.columns!='y']\n","\n","# data preprocess\n","# Standardize data\n","scaler = StandardScaler() \n","scaled_df = scaler.fit_transform(X) \n","  \n","# Normalizing the Data \n","normalized_df = normalize(scaled_df) \n","  \n","# Converting the numpy array into a pandas DataFrame \n","X = pd.DataFrame(normalized_df) \n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["(41257, 696)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["X.shape"]},{"cell_type":"markdown","metadata":{},"source":["## ExKMC algorithm"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# kmeans pre train\n","k = 2\n","n = X.shape[0]\n","\n","\n","kmeans = KMeans(k, random_state=42)\n","kmeans.fit(X)\n","\n","# confusion_matrix\n","# plot_confusion_matrix(y, kmeans.predict(X), np.array(list(X_.columns)), normalize=True)\n","\n","def visualize_2d(data):\n","    from sklearn.decomposition import PCA\n","    pca = PCA(2)\n","    df = pca.fit_transform(data.to_numpy())\n","\n","    kmeans_2 = KMeans(k, random_state=42)\n","    kmeans_2.fit(df)\n","\n","    plot_kmeans(kmeans_2, x_data =df)\n","\n","    tree_n = Tree(k)\n","    tree_n.fit(df, kmeans_2)\n","\n","    plot_tree_boundary(tree_n, k, df, kmeans_2, plot_mistakes=True)\n","\n","# visualize_2d(X)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Initialize tree with up to 6 leaves, predicting 3 clusters\n","tree = Tree(k=k)\n","\n","# Construct the tree, and return cluster labels\n","# prediction = tree.fit_predict(X,kmeans)\n","tree.fit(X, kmeans)\n","\n","# Tree plot saved to filename\n","tree.plot(\"test\",feature_names=list(X_.columns))"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["kmeans_cost is 37179.87612739552 \n"," surrogate_score is 37290.76841843778\n"," kmenas cost in surrogate is -36683.55002984238\n"]}],"source":["# cost\n","# kmeas cost in paper: The k-means cost is the sum of squared distances of each point to the mean of points associated with the cluster.\n","# kmenas cost in sklearn:Opposite of the value of X on the K-means objective.\n","# surrogate cost:The k-means surrogate cost is the sum of squared distances of each point to the closest center of the kmeans given (or trained) in the fit method.k-means surrogate cost > k-means cost, as k-means cost is computed with respect to the optimal centers.\n","\n","kmeas_cost = tree.score(X)\n","surrogate_score = tree.surrogate_score(X)\n","print(f\"kmeans_cost is {kmeas_cost} \\nsurrogate_score is {surrogate_score}\\nkmenas cost in surrogate is {kmeans.score(X)}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## ICOT algorithm"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNrV8z86W1ElNSu4E21X3YW","provenance":[]},"kernelspec":{"display_name":"Python 3.9.13 ('thesis')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"c673639e1878fb3520d597d27aecf39bb774213fc27bbc445709cd358b48682f"}}},"nbformat":4,"nbformat_minor":0}
