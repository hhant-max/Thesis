{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17707,"status":"ok","timestamp":1668445295774,"user":{"displayName":"孙菲阳","userId":"00080526783451141965"},"user_tz":-60},"id":"WAi8dgc-J5Jn","outputId":"30dfbcaf-271f-49d4-e455-959ebdbae8f0"},"outputs":[],"source":["%matplotlib inline\n","from ExKMC.Tree import Tree\n","from sklearn.datasets import make_blobs\n","import gdown\n","import pandas as pd\n","import copy\n","from sklearn.cluster import KMeans\n","from utils import calc_cost, plot_kmeans, plot_tree_boundary,plot_confusion_matrix\n","from sklearn.preprocessing import StandardScaler, normalize\n","from utils import plot_confusion_matrix\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import os\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# print(os.path.join(os.path.dirname(__file__),\"./data/negtive.csv\"))\n","# print(os.path.join(os.path.abspath('algorithms/Kmeans+.ipynb'),\"./data/negtive.csv\"))\n","# print(os.path.abspath('algorithms/Kmeans+.ipynb'))"]},{"cell_type":"markdown","metadata":{},"source":["## data preprocessing"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# input data\n","def getDataDrive(url, output, isImport=False):\n","    \"\"\"\n","    return pandas dataframe\n","    \"\"\"\n","    if isImport:\n","        gdown.download(url=url, output=output, quiet=False)\n","    res = pd.read_csv(output)\n","    return res\n","\n","\n","neg = getDataDrive(\n","    url=\"https://drive.google.com/uc?id=1ocidTn7jUvCrLG_XJ6H9MiNUDexCkjFG\",\n","    output='/home/sfy/Documents/VScodeProject/Thesis/data/negtive.csv'\n",")\n","pos = getDataDrive(\n","    url=\"https://drive.google.com/uc?id=1IyMPjACBkz96giGJ-Z4IMk-qzM-1CJ9G\",\n","    output='/home/sfy/Documents/VScodeProject/Thesis/data/positive.csv',\n",")\n","\n","X_neg = copy.deepcopy(neg)\n","X_pos = copy.deepcopy(pos)\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["pos_target = [1 for _ in range(X_pos.shape[0])]\n","neg_target = [0 for _ in range(X_neg.shape[0])]\n","\n","X_pos['y'] = pos_target\n","X_neg['y'] = neg_target\n","\n","X__ = pd.concat([X_pos,X_neg])\n","\n","# exclue name -> X_\n","X_ = X__.loc[:, X__.columns!='name']\n","\n","# exclude label -> X\n","y = X_['y']\n","X = X_.loc[:, X_.columns!='y']\n","\n","# data preprocess\n","# Standardize data\n","# TODO train_test_split(X, y, test_size=0.4, random_state=0)\n","\n","scaler = StandardScaler() \n","scaled_df = scaler.fit_transform(X) \n","  \n","# Normalizing the Data \n","normalized_df = normalize(scaled_df) \n","  \n","# Converting the numpy array into a pandas DataFrame \n","X = pd.DataFrame(normalized_df) \n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["(41257, 696)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["X.shape"]},{"cell_type":"markdown","metadata":{},"source":["## ExKMC algorithm"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# kmeans pre train\n","k = 2\n","n = X.shape[0]\n","\n","\n","kmeans = KMeans(k, random_state=42)\n","kmeans.fit(X)\n","\n","# confusion_matrix\n","# plot_confusion_matrix(y, kmeans.predict(X), np.array(list(X_.columns)), normalize=True)\n","\n","def visualize_2d(data):\n","    from sklearn.decomposition import PCA\n","    pca = PCA(2)\n","    df = pca.fit_transform(data.to_numpy())\n","\n","    kmeans_2 = KMeans(k, random_state=42)\n","    kmeans_2.fit(df)\n","\n","    plot_kmeans(kmeans_2, x_data =df)\n","\n","    tree_n = Tree(k)\n","    tree_n.fit(df, kmeans_2)\n","\n","    plot_tree_boundary(tree_n, k, df, kmeans_2, plot_mistakes=True)\n","\n","# visualize_2d(X)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["cluster_labels = kmeans.fit_predict(X)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["array([[-0.00569809, -0.0144497 , -0.01241951, ...,  0.        ,\n","         0.        ,  0.        ],\n","       [-0.03171698, -0.01341128, -0.00573732, ...,  0.        ,\n","         0.        ,  0.        ]])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["kmeans.cluster_centers_"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["13"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["kmeans.n_iter_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# test with inter \n","def inter_visual():\n","    from yellowbrick.cluster import InterclusterDistance\n","    visualizer = InterclusterDistance(kmeans)\n","    visualizer.fit(X)\n","    visualizer.show()\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["<ExKMC.Tree.Tree at 0x7f84e33e36d0>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize tree with up to 6 leaves, predicting 3 clusters\n","tree = Tree(k=k)\n","\n","# Construct the tree, and return cluster labels\n","# prediction = tree.fit_predict(X,kmeans)\n","tree.fit(X, kmeans)\n","\n","# Tree plot saved to filename\n","# tree.plot(\"test\",feature_names=list(X_.columns))"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["tree_labels = tree.fit_predict(X,kmeans)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["array([0., 0., 0., ..., 0., 0., 1.])"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["tree_labels"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["kmeans_cost is 37179.87612739552 \n","surrogate_score is 37290.76841843778\n","kmenas cost in surrogate is -36683.55002984239\n"]}],"source":["# cost\n","# kmeas cost in paper: The k-means cost is the sum of squared distances of each point to the mean of points associated with the cluster.\n","# kmenas cost in sklearn:Opposite of the value of X on the K-means objective.\n","# surrogate cost:The k-means surrogate cost is the sum of squared distances of each point to the closest center of the kmeans given (or trained) in the fit method.k-means surrogate cost > k-means cost, as k-means cost is computed with respect to the optimal centers.\n","\n","kmeas_cost = tree.score(X)\n","surrogate_score = tree.surrogate_score(X)\n","print(f\"kmeans_cost is {kmeas_cost} \\nsurrogate_score is {surrogate_score}\\nkmenas cost in surrogate is {kmeans.score(X)}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation"]},{"cell_type":"markdown","metadata":{},"source":["### inter and intra distance"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["from scipy.spatial import distance"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# intra\n","\n","# inter\n","#centroids\n","\n","dst = distance.euclidean(kmeans.cluster_centers_[0], kmeans.cluster_centers_[1])\n","# kmeans.cluster_centers_"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["0.5800166565176593"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["dst"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tree.get_ce"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append('../')\n","# sys.path.insert(0, '/home/amninder/Desktop/Folder_2')"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["from ExKMC_M.ExKMC.Tree import Tree"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["<ExKMC_M.ExKMC.Tree.Tree at 0x7f84b62bbfd0>"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["tree = Tree(k=k)\n","tree.fit(X, kmeans)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":["array([[-0.17344127, -0.07444386, -0.02251826, ...,  0.        ,\n","         0.        ,  0.        ],\n","       [ 0.18619418,  0.07991762,  0.02417399, ...,  0.        ,\n","         0.        ,  0.        ]])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["tree.get_centers()"]},{"cell_type":"markdown","metadata":{},"source":["### other useful build-in matrics (needs to implement one attribute)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["from time import time\n","from sklearn import metrics\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","def bench_k_means(kmeans, name, data, labels):\n","    \"\"\"Benchmark to evaluate the KMeans initialization methods.\n","\n","    Parameters\n","    ----------\n","    kmeans : KMeans instance\n","        A :class:`~sklearn.cluster.KMeans` instance with the initialization\n","        already set.\n","    name : str\n","        Name given to the strategy. It will be used to show the results in a\n","        table.\n","    data : ndarray of shape (n_samples, n_features)\n","        The data to cluster.\n","    labels : ndarray of shape (n_samples,)\n","        The labels used to compute the clustering metrics which requires some\n","        supervision.\n","    \"\"\"\n","    t0 = time()\n","    estimator = make_pipeline(StandardScaler(), kmeans).fit(data)\n","    fit_time = time() - t0\n","    results = [name, fit_time, estimator[-1].inertia_]\n","\n","    # Define the metrics which require only the true labels and estimator\n","    # labels\n","    clustering_metrics = [\n","        metrics.homogeneity_score,\n","        metrics.completeness_score,\n","        metrics.v_measure_score,\n","        metrics.adjusted_rand_score,\n","        metrics.adjusted_mutual_info_score,\n","    ]\n","    results += [m(labels, estimator[-1].labels_) for m in clustering_metrics]\n","\n","    # The silhouette score requires the full dataset\n","    results += [\n","        metrics.silhouette_score(\n","            data,\n","            estimator[-1].labels_,\n","            metric=\"euclidean\",\n","            sample_size=300,\n","        )\n","    ]\n","\n","    # Show the results\n","    formatter_result = (\n","        \"{:9s}\\t{:.3f}s\\t{:.0f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\"\n","    )\n","    print(formatter_result.format(*results))\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["kmeans   \t7.233s\t16612858\t0.017\t0.017\t0.017\t0.024\t0.017\t0.103\n"]}],"source":["bench_k_means(kmeans=kmeans,name='kmeans',data=X,labels=y)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# bench_k_means(kmeans=tree,name='tree',data=X,labels=y)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNrV8z86W1ElNSu4E21X3YW","provenance":[]},"kernelspec":{"display_name":"Python 3.8.15 ('thesis8')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15"},"vscode":{"interpreter":{"hash":"518c84c64c8714e835d71f45ff9dbbd66c2334f2195057bfe969113e9082ddb2"}}},"nbformat":4,"nbformat_minor":0}
